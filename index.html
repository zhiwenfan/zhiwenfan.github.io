<!DOCTYPE html>
<!-- saved from url=(0017)https://xzhou.me/ -->
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><!--<base target="_blank">-->
    <base href="." target="_blank">
    <link rel="preconnect" href="https://fonts.gstatic.com/">
    <link rel="stylesheet" type="text/css" data-href="https://fonts.googleapis.com/css?family=Lato">
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin="">
    <meta name="viewport" content="width=device-width">
    <title>Zhiwen Fan's Homepage</title>
    <meta name="description" content="I am a Ph.D. student in Electrical Engineering at The University of Texas at Austin">
    <meta name="next-head-count" content="4">
    <link rel="preload" href="./Homepage_files/fd4c9bf86266e80fae27.css" as="style">
    <link rel="stylesheet" href="./Homepage_files/fd4c9bf86266e80fae27.css" data-n-g="">
    <link rel="preload" href="./Homepage_files/a515be4c2f49419f3769.css" as="style">
    <link rel="stylesheet" href="./Homepage_files/a515be4c2f49419f3769.css" data-n-p=""><noscript
        data-n-css=""></noscript>
    <script defer="" nomodule="" src="./Homepage_files/polyfills-a54b4f32bdc1ef890ddd.js.下载"></script>
    <script src="./Homepage_files/webpack-715970c8028b8d8e1f64.js.下载" defer=""></script>
    <script src="./Homepage_files/framework-64eb7138163e04c228e4.js.下载" defer=""></script>
    <script src="./Homepage_files/main-c94e7f60255631414010.js.下载" defer=""></script>
    <script src="./Homepage_files/_app-3fa27215a3c41987e6d2.js.下载" defer=""></script>
    <script src="./Homepage_files/688-b942890a87f9a08b0e31.js.下载" defer=""></script>
    <script src="./Homepage_files/index-335648998a7bdac0c719.js.下载" defer=""></script>
    <script src="./Homepage_files/_buildManifest.js.下载" defer=""></script>
    <script src="./Homepage_files/_ssgManifest.js.下载" defer=""></script>
    <style data-href="https://fonts.googleapis.com/css?family=Lato">
        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v24/S6uyw4BMUTPHjx4wWA.woff) format('woff')
        }

        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v24/S6uyw4BMUTPHjxAwXiWtFCfQ7A.woff2) format('woff2');
            unicode-range: U+0100-02AF, U+0304, U+0308, U+0329, U+1E00-1E9F, U+1EF2-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF
        }

        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v24/S6uyw4BMUTPHjx4wXiWtFCc.woff2) format('woff2');
            unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+0304, U+0308, U+0329, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD
        }
    </style>
</head>

<body>
    <div id="__next">
        <div class="styles_container__1_WuM">
            <section>
                <div class="personal_profile__BdQI4"><img class="personal_portrait__BAkO0"
                        src="./Homepage_files/portrait.jpg" alt="pottrait">
                    <div class="personal_profileInfo__1Y4pW">
                        <h1 class="personal_name__1_mHK">Zhiwen Fan</h1>
                        <h3 class="personal_chineseName__18aOD">樊志文</h3>
                        <h3 class="personal_worksFor__2L0De">University of Texas at Austin</h3>
                        <div class="personal_links__p_eYL"><span><a
                                    href="mailto:zhiwenfan@utexas.edu">Email</a></span><span><a
                                    href="https://scholar.google.com.hk/citations?user=tdoBO3UAAAAJ&hl=en-us">Google
                                    Scholar</a></span><span><a href="./Homepage_files/Zhiwen_Fan_CV.pdf">CV</a></span></div>
                    </div>
                </div>
            </section>
            <section>
                <h2>About Me</h2>
                <div>
                    <p>I am a Ph.D. student in Electrical Engineering at The University of Texas at Austin advised by <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang">Prof. Atlas Wang</a> at <a href="https://vita-group.github.io/">VITA group</a>.
                        Previously, I was a senior algorithm engineer at <a href="https://ailab.aliyun.com/">Alibaba Cloud</a> worked with <a href="https://scholar.google.com/citations?user=XhyKVFMAAAAJ&hl=en">Prof. Ping Tan</a> and <a href="https://sites.google.com/site/zhusiyucs/home">Prof. Siyu Zhu</a>.
                        I am a winner of <a href="https://www.qualcomm.com/research/university-relations/innovation-fellowship/2022-north-america">Qualcomm Innovation Fellowship 2022</a>.
                    </p>
                </div>
            </section>
            <section>
                <h2>Recent News</h2>
                <ul>
                    <li>One paper for 3DV 2024, three papers for CVPR 2024 (one as highlight), three papers for ECCV 2024, one paper for IROS 2024, have been accepted. </li>
                    <li>One paper for ASP-DAC 2023, one for CVPR 2023 (as highlight), and two for ICCV 2023 have been accepted. </li>
                    <li>We won the Qualcomm Innovation Fellowship (North America) 2022 <a href="https://www.qualcomm.com/research/university-relations/innovation-fellowship/2022-north-america">(QIF 2022)</a>. </li>
                    <li>We won 3rd place in the University Demo Best Demonstration at the 59th Design Automation Conference <a href="https://www.dac.com/">(DAC 2022)</a>. </li>
                    <li>Two papers for CVPR 2022 (one as oral), one for ICML 2022, three for ECCV 2022, and two for NeurIPS 2022 have been accepted. </li>
                    <li>One paper for ICCV 2021, one for 3DV 2021 have been accepted. </li>
                    <li>One paper for CVPR 2020 (as oral), one for TIP have been accepted. </li>
                </ul>
                <!-- <div class="styles_showMore__JvZFs"><button>Show More</button></div> -->
            </section>
            <section>
                <h2>Selected Publications<br class="publication-list_mobileBreak__24vsO"><span
                        class="publication-list_filters__3ikvu"><span>Full publication list at </span><span><a
                                href="https://scholar.google.com.hk/citations?hl=en&user=tdoBO3UAAAAJ&view_op=list_works&sortby=pubdate">Google
                                Scholar</a></span></span></h2>
                <div class="publication-list_smallText__pUJXB">* denotes equal contribution.</div>
                <div>

                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/lsm.mp4"
                            title="Large Spatial Model video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Large Spatial Model: Real-time Unposed Images to Semantic 3D</div>
                            <div class="publication_authors__qkFXc"><span>Zhiwen Fan*, Jian Zhang*, Wenyan Cong, Peihao Wang, Renjie Li, Kairun Wen, Shijie Zhou, Achuta Kadambi,  Zhangyang Wang, Danfei Xu, Boris Ivanovic, Marco Pavone, Yue Wang </span></div>
                            <div class="publication_venue__1Dv6R"><span>Preprint</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://largespatialmodel.github.io/">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://largespatialmodel.github.io/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://largespatialmodel.github.io/">Code</a></span></div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/4k4dgen.mp4"
                            title="4K4DGen video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">4K4DGen: Panoramic 4D Generation at 4K Resolution</div>
                            <div class="publication_authors__qkFXc"><span>Renjie Li, Panwang Pan, Dejia Xu, Shijie Zhou, Xuanyang Zhang, Zeming Li, Achuta Kadambi, Zhangyang Wang, Zhiwen Fan    </span></div>
                            <div class="publication_venue__1Dv6R"><span>Preprint</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://4k4dgen.github.io/">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://4k4dgen.github.io/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://4k4dgen.github.io/">Code</a></span></div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/instantsplat.mp4"
                            title="Instantsplat video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds</div>
                            <div class="publication_authors__qkFXc"><span>Zhiwen Fan*, Wenyan Cong*, Kairun Wen*, Kevin Wang, Jian Zhang, Xinghao Ding, Danfei Xu, Boris Ivanovic, Marco Pavone, Georgios Pavlakos, Zhangyang Wang, Yue Wang </span></div>
                            <div class="publication_venue__1Dv6R"><span>Preprint</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2403.20309">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://instantsplat.github.io/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://instantsplat.github.io/">Code</a></span></div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/garden_lighgaussian.mp4"
                            title="LightGaussian video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan*</span></span><span><span>Kevin</span>
                                    <span>Wang*</span></span><span><span>Kairun </span>
                                    <span>Wen</span></span><span><span>Zehao </span>
                                    <span>Zhu</span></span><span><span>Dejia </span>
                                    <span>Xu</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>Preprint</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2311.17245">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://lightgaussian.github.io/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/LightGaussian">Code</a></span></div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/dreamscene360.mp4"
                            title="dreamscene360 video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting</div>
                            <div class="publication_authors__qkFXc"><span>Zhiwen Fan*, Shijie Zhou*, Dejia Xu*, Haoran Chang, Pradyumna Chari, Tejas Bharadwaj, Suya You, Zhangyang Wang, Achuta Kadambi </span></div>
                            <div class="publication_venue__1Dv6R"><span>ECCV 2024</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2404.06903">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://dreamscene360.github.io/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://dreamscene360.github.io/">Code</a></span></div>
                        </div>
                    </div>

                    <!-- <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/fsgs.mp4"
                            title="FSGS video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">FSGS: Real-Time Few-shot View Synthesis using Gaussian Splatting</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan*</span></span><span><span>Zehao</span>
                                    <span>Zhu*</span></span><span><span>Yifan</span>
                                    <span>Jiang</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>Preprint</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2312.00451">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://zehaozhu.github.io/FSGS/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/FSGS">Code</a></span></div>
                        </div>
                    </div> -->

                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/feature-3dgs.mp4"
                            title="Feature 3DGS video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled Feature Fields</div>
                            <div class="publication_authors__qkFXc">
                                    Shijie Zhou, Haoran Chang, Sicheng Jiang, Zhiwen Fan, Zehao Zhu, Dejia Xu, Pradyumna Chari, Suya You, Zhangyang Wang, Achuta Kadambi,</span>
                                    </div>
                            <div class="publication_venue__1Dv6R"><span>CVPR 2024</span><span class="publication_highlights__2ILmf">(Highlight, 2.8% of 11532)</span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2312.03203">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://feature-3dgs.github.io/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/ShijieZhou-UCLA/feature-3dgs">Code</a></span></div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/tamingtext23d.mp4"
                            title="Taming... video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Taming Mode Collapse in Score Distillation for Text-to-3D Generation</div>
                            <div class="publication_authors__qkFXc">
                                    Peihao Wang, Dejia Xu, Zhiwen Fan, Dilin Wang, Sreyas Mohan, Forrest Iandola, Rakesh Ranjan, Yilei Li, Qiang Liu, Zhangyang Wang, Vikas Chandra,</span>
                                    </div>
                            <div class="publication_venue__1Dv6R"><span>CVPR 2024</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2401.00909">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://vita-group.github.io/3D-Mode-Collapse/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/3D-Mode-Collapse">Code</a></span></div>
                        </div>
                    </div>

                    <!-- <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/pf-grt.mp4"
                            title="PF-GRT video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Pose-Free Generalizable Rendering Transformer</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan*</span></span><span><span>Panwang</span>
                                    <span>Pan*</span></span><span><span>Peihao</span>
                                    <span>Wang</span></span><span><span>Yifan</span>
                                    <span>Jiang</span></span><span><span>Hanwen </span>
                                    <span>Jiang</span></span><span><span>Dejia </span>
                                    <span>Xu</span></span><span><span>Zehao </span>
                                    <span>Zhu</span></span><span><span>Dilin </span>
                                    <span>Wang</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>Preprint</span><span></span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2310.03704">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://zhiwenfan.github.io/PF-GRT/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/zhiwenfan/PF-GRT">Code</a></span></div>
                        </div>
                    </div> -->

                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/nerf_sos.mp4"
                            title="NeRF-SOS video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">NeRF-SOS: Any-View Self-supervised Object Segmentation from Complex Real-World Scenes</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan</span></span><span><span>Peihao</span>
                                    <span>Wang</span></span><span><span>Yifan</span>
                                    <span>Jiang</span></span><span><span>Xinyu </span>
                                    <span>Gong</span></span><span><span>Dejia </span>
                                    <span>Xu</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>ICLR</span><span>2023</span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://openreview.net/pdf?id=kfOtMqYJlUU">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://zhiwenfan.github.io/NeRF-SOS/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/NeRF-SOS">Code</a></span></div>
                        </div>
                    </div>

                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/neuralift360_merge.mp4"
                            title="NeuralLift-360 video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360° Views</div>
                            <div class="publication_authors__qkFXc"><span><span>Dejia</span>
                                    <span>Xu</span></span><span><span>Yifan</span>
                                    <span>Jiang</span></span><span><span>Peihao</span>
                                    <span>Wang</span></span><span><span>Zhiwen </span>
                                    <span>Fan</span></span><span><span>Yi </span>
                                    <span>Wang</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>CVPR</span><span>2023</span>&nbsp;  <span
                                class="publication_highlights__2ILmf">(Highlight, 2.5% of 9155)</span></div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2211.16431">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://vita-group.github.io/NeuralLift-360/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/NeuralLift-360">Code</a></span></div>
                        </div>
                    </div>

                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/INS_merge.mp4"
                                title="INS video loading.." playsinline="" autoplay="" loop="" preload=""
                                muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Unified Implicit Neural Stylization</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan*</span></span><span><span>Yifan</span>
                                    <span>Jiang*</span></span><span><span>Peihao</span>
                                    <span>Wang*</span></span><span><span>Xinyu </span>
                                    <span>Gong</span></span><span><span>Dejia</span>
                                    <span>Xu</span></span><span><span>Zhangyang</span> <span>Wang</span></span></div>
                            <div class="publication_venue__1Dv6R"><span>ECCV</span><span>2022</span>&nbsp; </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2204.01943">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://zhiwenfan.github.io/INS/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/INS">Code</a></span></div>
                        </div>
                    </div>
                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="./Homepage_files/videos/m3vit.png"
                                alt="M^3ViT Video thumbnail loading...">
                        </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">M^3ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen </span>
                                    <span>Fan*</span></span><span><span>Hanxue </span>
                                    <span>Liang*</span></span><span><span>Rishov </span>
                                    <span>Sarkar</span></span><span><span>Ziyu </span>
                                    <span>Jiang</span></span><span><span>Tianlong </span>
                                    <span>Chen</span></span><span><span>Kai </span>
                                    <span>Zou</span></span><span><span>Yu </span>
                                    <span>Cheng</span></span><span><span>Cong  </span>
                                    <span>Hao</span></span><span><span>Zhangyang   </span>
                                    <span>Wang</span>
                                </div>
                            <div class="publication_venue__1Dv6R"><span>NeurIPS</span><span>2022</span>&nbsp;
                                <span
                                class="publication_highlights__2ILmf">(QIF 2022 Award)</span>
                            </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://openreview.net/pdf?id=cFOhdl1cyU-">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/M3ViT">Code</a></span></div>
                        </div>
                    </div>
                    <!-- <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video src="./Homepage_files/videos/sinnerf_merge.mp4"
                            title="INS video loading.." playsinline="" autoplay="" loop="" preload=""
                            muted=""></video></div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image
                            </div>
                            <div class="publication_authors__qkFXc"><span><span>Dejia </span>
                                    <span>Xu*</span></span><span><span>Yifan</span>
                                    <span>Jiang*</span></span><span><span>Peihao </span>
                                    <span>Wang</span></span><span><span>Zhiwen </span>
                                    <span>Fan</span></span><span><span>Humphery </span>
                                    <span>Shi</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>ECCV</span><span>2022</span>&nbsp;
                            </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2204.00928">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://vita-group.github.io/SinNeRF/">Project</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/SinNeRF">Code</a></span></div>
                        </div>
                    </div> -->
                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="./Homepage_files/videos/floorplancad.png"
                            alt="CADTransformer...">
                    </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen </span>
                                    <span>Fan</span></span><span><span>Tianlong </span>
                                    <span>Chen</span></span><span><span>Peihao </span>
                                    <span>Wang</span></span><span><span>Zhangyang </span>
                                    <span>Wang</span></div>
                            <div class="publication_venue__1Dv6R"><span>CVPR</span><span>2022</span>&nbsp;<span
                                class="publication_highlights__2ILmf">(Oral Presentation, top 5% in all submissions)</span> </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://openaccess.thecvf.com/content/CVPR2022/html/Fan_CADTransformer_Panoptic_Symbol_Spotting_Transformer_for_CAD_Drawings_CVPR_2022_paper.html">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/VITA-Group/CADTransformer">Code</a></span></div>
                        </div>
                    </div>

                    <!-- <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="./Homepage_files/videos/floorplancad.png"
                            alt="FloorPlanCAD...">
                    </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">FloorPlanCAD: A Large-Scale CAD Drawing Dataset for Panoptic Symbol Spotting</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen </span>
                                    <span>Fan*</span></span><span><span>Lingjie  </span>
                                    <span>Zhu*</span></span><span><span>Honghua </span>
                                    <span>Li</span></span><span><span>Xiaohao </span>
                                    <span>Chen</span></span><span><span>Siyu   </span>
                                    <span>Zhu</span></span><span><span>Ping   </span>
                                    <span>Tan</span></div>
                            <div class="publication_venue__1Dv6R"><span>ICCV</span><span>2021</span>&nbsp;</div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2105.07147">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://zhiwenfan.github.io/images/floorplancad_poster.pdf">Poster</a></span>
                                    <span
                                    class="publication_link__fXY43"><a
                                        href="https://www.youtube.com/watch?v=rcJiRQqDKbo">Video</a></span></div>
                        </div>
                    </div> -->


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="./Homepage_files/videos/cascadecostvolume.jpeg"
                            alt="CascadeCostVolume...">
                    </div>
                    <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan*</span></span><span><span>Xiaodong </span>
                                    <span>Gu*</span></span><span><span>Siyu </span>
                                    <span>Zhu</span></span><span><span>Zuozhuo</span>
                                    <span>Dai</span></span><span><span>Feitong   </span>
                                    <span>Tan</span></span><span><span>Ping</span>
                                    <span>Tan</span></div>
                            <div class="publication_venue__1Dv6R"><span>CVPR</span><span>2020</span>&nbsp;<span
                                class="publication_highlights__2ILmf">(Oral Presentation, top 5% in all submissions)</span> </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/1912.06378">Paper</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://www.youtube.com/watch?v=rcJiRQqDKbo">Video</a></span><span
                                    class="publication_link__fXY43"><a
                                        href="https://github.com/alibaba/cascade-stereo">Code</a></span>
                            </div>
                        </div>
                    </div>

                    <!-- <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="./Homepage_files/videos/disn-tip.png"
                            alt="CascadeCostVolume...">
                    </div>
                    <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">A Deep Information Sharing Network for Multi-contrast Compressed Sensing MRI Reconstruction</div>
                            <div class="publication_authors__qkFXc"><span><span>Liyan</span>
                                    <span>Sun</span></span><span><span>Zhiwen </span>
                                    <span>Fan</span></span><span><span>Xueyang  </span>
                                    <span>Fu</span></span><span><span>Xinghao  </span>
                                    <span>Ding</span></span><span><span>Yue </span>
                                    <span>Huang</span></span><span><span>John    </span>
                                    <span>Paisley</span></div>
                            <div class="publication_venue__1Dv6R"><span>IEEE Transactions on Image Processing</span><span>2020</span>&nbsp; </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/1805.02165">Paper</a></span>
                            </div>
                        </div>
                    </div> -->



                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="./Homepage_files/videos/SegMRI-ipmi.jpeg"
                            alt="CascadeCostVolume...">
                    </div>
                    <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Joint CS-MRI Reconstruction and Segmentation with a Unified Deep Network</div>
                            <div class="publication_authors__qkFXc"><span><span>Zhiwen</span>
                                    <span>Fan*</span></span><span><span>Liyan </span>
                                    <span>Sun*</span></span><span><span>Xinghao  </span>
                                    <span>Ding</span></span><span><span>Yue </span>
                                    <span>Huang</span></span><span><span>John    </span>
                                    <span>Paisley</span></div>
                            <div class="publication_venue__1Dv6R"><span>IPMI</span><span>2019</span>&nbsp; </div>
                            <div class="publication_links__aEpO_"><span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/1805.02165">Paper</a></span>
                            </div>
                        </div>
                    </div>


                </div>
            </section>
            <section>
                <h2>Experience</h2>
                <ul>
                    <li>
                        <div style="display:inline">
                            Meta, Redmond<!-- -->: </div><span
                            class="styles_collaborator__VflHz">Research Intern (year of 2023)</span>.
                    </li>
                    <li>
                        <div style="display:inline">
                            Google, San Francisco<!-- -->: </div><span
                            class="styles_collaborator__VflHz">Research Intern (year of 2022)</span>.
                    </li>
                    <li>
                        <div style="display:inline">
                            	Alibaba Group, Hangzhou<!-- -->: </div><span
                            class="styles_collaborator__VflHz">Senior Algorithm Engineer(2019 - 2021)</span>.
                    </li>
                </ul>
            </section>
            <section>
                <h2>Services</h2>
                <ul>
                    <li>
                        <div style="display:inline">
                            Journal Reviewers:&nbsp;</div><span
                            class="styles_collaborator__VflHz">TPAMI, TIP, IJCV, Neurocomputing</span>.
                    </li>
                    <li>
                        <div style="display:inline">
                            Conference  Reviewers:&nbsp;</div><span
                            class="styles_collaborator__VflHz">NeurIPS 22/23, ICML 22/23, CVPR 22/23, ICCV 21/23, AAAI 21, ICME 2019</span>.
                    </li>
                </ul>
            </section>
            <footer class="styles_footer__3qp3V">
                <p>Last updated on <time datetime="Sep 10 2023">Sep 18, 2023</time></p>
                <p> The website template was originally borrowed from <a href="https://www.xzhou.me/">[1] </a>and <a href="https://yifanjiang19.github.io/">[2]</a>, thanks!.</p>
            </footer>
        </div>
    </div>

</body>

</html>